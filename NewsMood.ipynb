{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Mood Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules and info\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authenticate tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile list of twitter handles through which to loop\n",
    "handles = [\"@BBCNews\", \"@CBSNews\", \"@CNN\", \"@FoxNews\", \"@nytimes\"]\n",
    "\n",
    "#create a list to hold dictionaries of the sentiment analysis resules\n",
    "s_scores = []\n",
    "\n",
    "#create a variable to store the oldest tweet id for the loop\n",
    "ot = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the news organizations\n",
    "for handle in handles:\n",
    "    \n",
    "    #create counter for tabulating tweets\n",
    "    c = 1\n",
    "    \n",
    "    #loop through 5 pages (20 tweets per page) of tweets to acquire 100 tweets\n",
    "    for x in range(5):\n",
    "        tweets = api.user_timeline(handle, max_id = ot)\n",
    "    \n",
    "        #loop through the tweets themselves\n",
    "        for t in tweets:\n",
    "            \n",
    "            #run Vader analysis on the tweet\n",
    "            scores = analyzer.polarity_scores(t[\"text\"])\n",
    "            \n",
    "            #add dictionary of scores to the list along with the media source date stamp\n",
    "            s_scores.append({\"Media Source\": t[\"user\"][\"name\"],\n",
    "                            \"Date\": t[\"created_at\"],\n",
    "                           \"Text\": t[\"text\"],\n",
    "                           \"Compound\": scores[\"compound\"],\n",
    "                           \"Positive\": scores[\"pos\"],\n",
    "                           \"Negative\": scores[\"neu\"],\n",
    "                           \"Neutral\": scores[\"neg\"],\n",
    "                           \"Tweets Ago\": c})\n",
    "            \n",
    "            # store the tweet id in the oldest tweet variable and subtract 1 to continue iteration\n",
    "            ot = t['id'] - 1\n",
    "            \n",
    "            #increase the counter to document the next tweet\n",
    "            c += 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Media Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tweets Ago</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC News (UK)</td>\n",
       "      <td>Fri Jul 27 16:53:00 +0000 2018</td>\n",
       "      <td>RT @BBCPanorama: Stockton-on-Tees is the town ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.7906</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBC News (UK)</td>\n",
       "      <td>Fri Jul 27 16:34:03 +0000 2018</td>\n",
       "      <td>ðŸ“µ Get ready for Scroll Free September ðŸ“µ\\n\\nhtt...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBC News (UK)</td>\n",
       "      <td>Fri Jul 27 16:29:35 +0000 2018</td>\n",
       "      <td>Christine Lampard's stalker Christof King sent...</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBC News (UK)</td>\n",
       "      <td>Fri Jul 27 16:16:02 +0000 2018</td>\n",
       "      <td>Drill music video stop and search by armed pol...</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBC News (UK)</td>\n",
       "      <td>Fri Jul 27 16:09:52 +0000 2018</td>\n",
       "      <td>RT @BBCNewsbeat: The incident was described as...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Media Source                            Date  \\\n",
       "0  BBC News (UK)  Fri Jul 27 16:53:00 +0000 2018   \n",
       "1  BBC News (UK)  Fri Jul 27 16:34:03 +0000 2018   \n",
       "2  BBC News (UK)  Fri Jul 27 16:29:35 +0000 2018   \n",
       "3  BBC News (UK)  Fri Jul 27 16:16:02 +0000 2018   \n",
       "4  BBC News (UK)  Fri Jul 27 16:09:52 +0000 2018   \n",
       "\n",
       "                                                Text  Tweets Ago  Compound  \\\n",
       "0  RT @BBCPanorama: Stockton-on-Tees is the town ...           1   -0.7906   \n",
       "1  ðŸ“µ Get ready for Scroll Free September ðŸ“µ\\n\\nhtt...           2    0.7003   \n",
       "2  Christine Lampard's stalker Christof King sent...           3   -0.0258   \n",
       "3  Drill music video stop and search by armed pol...           4   -0.2960   \n",
       "4  RT @BBCNewsbeat: The incident was described as...           5    0.0000   \n",
       "\n",
       "   Negative  Neutral  Positive  \n",
       "0     0.731    0.269     0.000  \n",
       "1     0.463    0.000     0.537  \n",
       "2     0.845    0.155     0.000  \n",
       "3     0.820    0.180     0.000  \n",
       "4     1.000    0.000     0.000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the list of dictionaries containing the scores into a DataFrame\n",
    "spd = pd.DataFrame(s_scores)\n",
    "spd = spd[[\"Media Source\", \"Date\", \"Text\", \"Tweets Ago\", \"Compound\", \"Negative\", \"Neutral\", \"Positive\"]]\n",
    "spd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the DataFrame to a csv\n",
    "spd.to_csv(\"100tweets_by_org.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add color coding into the the DataFrame by news organization\n",
    "spd.loc[spd['Media Source'].str.contains('BBC'), 'source_key'] = 'gold'\n",
    "spd.loc[spd['Media Source'].str.contains('CNN'), 'source_key'] = 'steelblue'\n",
    "spd.loc[spd['Media Source'].str.contains('CBS'), 'source_key'] = 'seagreen'\n",
    "spd.loc[spd['Media Source'].str.contains('Fox'), 'source_key'] = 'firebrick'\n",
    "spd.loc[spd['Media Source'].str.contains('York'), 'source_key'] = 'slateblue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27/2018 09:54\n"
     ]
    }
   ],
   "source": [
    "#get a datestamp in order to label the data\n",
    "datestamp = datetime.now().strftime(\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "#plt.figure(figsize = (15, 10))\n",
    "#plt.scatter(spd['Tweets Ago'], spd['Compound'], s=70, c=spd['source_key'], edgecolors='grey', alpha=0.6)\n",
    "#plt.title(\"Pyber Ride Sharing Data\")\n",
    "#plt.xlabel(\"Total Number of Rides (Per City)\")\n",
    "#plt.ylabel(\"Average Fare ($)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
